import { Context } from "../types";
import { ResponseFromLlm } from "../adapters/openai/helpers/completions";
import { CommentSimilaritySearchResult } from "../adapters/supabase/helpers/comment";
import { IssueSimilaritySearchResult } from "../adapters/supabase/helpers/issues";
import { recursivelyFetchLinkedIssues } from "../helpers/issue-fetching";
import { formatChatHistory } from "../helpers/format-chat-history";
import { optimizeContext } from "../helpers/issue";
import { DEFAULT_SYSTEM_MESSAGE } from "../adapters/openai/helpers/prompts";

/**
 * Asks a question to GPT and returns the response
 * @param context - The context object containing environment and configuration details
 * @param question - The question to ask GPT
 * @returns The response from GPT
 * @throws If no question is provided
 */
export async function askQuestion(context: Context<"issue_comment.created">, question: string) {
  if (!question) {
    throw context.logger.error("No question provided");
  }
  const { specAndBodies, streamlinedComments } = await recursivelyFetchLinkedIssues({
    context,
    owner: context.payload.repository.owner.login,
    repo: context.payload.repository.name,
    issueNum: context.payload.issue.number,
  });
  const formattedChat = await formatChatHistory(context, streamlinedComments, specAndBodies);
  context.logger.info(`${formattedChat.join("")}`);
  return await askGpt(context, question, formattedChat);
}

/**
 * Asks GPT a question and returns the completions
 * @param context - The context object containing environment and configuration details
 * @param question - The question to ask GPT
 * @param formattedChat - The formatted chat history to provide context to GPT
 * @returns completions - The completions generated by GPT
 **/
export async function askGpt(context: Context, question: string, formattedChat: string[]): Promise<ResponseFromLlm> {
  const {
    env: { UBIQUITY_OS_APP_NAME },
    config: { model, similarityThreshold },
  } = context;
  let similarComments: CommentSimilaritySearchResult[] = [];
  let similarIssues: IssueSimilaritySearchResult[] = [];
  try {
    similarComments = (await context.adapters.supabase.comment.findSimilarComments(question, 1 - similarityThreshold, "")) || [];
  } catch (error) {
    context.logger.error(`Error fetching similar comments: ${(error as Error).message}`);
  }
  try {
    similarIssues = (await context.adapters.supabase.issue.findSimilarIssues(question, 1 - similarityThreshold, "")) || [];
  } catch (error) {
    context.logger.error(`Error fetching similar issues: ${(error as Error).message}`);
  }
  let similarText = similarComments.map((comment: CommentSimilaritySearchResult) => comment.comment_plaintext);
  similarText.push(...similarIssues.map((issue: IssueSimilaritySearchResult) => issue.issue_plaintext));
  // Remove Null Results (Private Comments)
  similarText = similarText.filter((text) => text !== null);
  formattedChat = formattedChat.filter((text) => text !== null);
  // Optimize the context
  formattedChat = optimizeContext(formattedChat);
  // ReRank the results based on the question
  // const reRankedChat = formattedChat.length > 0 ? await context.adapters.voyage.reranker.reRankResults(formattedChat.filter(text => text !== ""), question, 300) : [];
  similarText = similarText.filter((text) => text !== "");
  const rerankedText = similarText.length > 0 ? await context.adapters.voyage.reranker.reRankResults(similarText, question) : [];
  return context.adapters.openai.completions.createCompletion({
    systemMessage: DEFAULT_SYSTEM_MESSAGE,
    prompt: question,
    model,
    additionalContext: rerankedText,
    localContext: formattedChat,
    groundTruths: ["typescript", "github", "cloudflare worker", "actions", "jest", "supabase", "openai"],
    botName: UBIQUITY_OS_APP_NAME,
  });
}
